---
layout: post
title: "重识Kafka-01:诞生背景"
permalink: /kafka_01/background/
---

# 指南
上一篇: [重识Kafka_00:序言](https://spikeryang.github.io/kafka_00/preview/)  
本篇的内容对应论文的摘要, 1.介绍, 2.相关工作
下一篇: [重识Kafka_02:架构设计](https://spikeryang.github.io/kafka_02/design/)  

# 摘要
设计者对Kafka的描述：  
- 用于低延迟地收集&&传输大容量日志数据的消息系统
- 同时适合在线和离线的消息消费
- 引入了一些非传统但是有用的设计使系统高效，scalable(可扩展)

# 介绍 & 相关工作
设计者对当时消息系统的分析（为什么不适合日志处理？）：
- 关注消息传递的可靠性，提供事务消息、消费后ack。这些特性对于日志收集的场景来说是没有必要的，只会增加API和系统实现的复杂性，因为日志收集允许发生一些丢失
- 很多系统并不关注throughput，不支持batch批量发送。这意味着每条消息都需要一次完整的TCP/IP连接，严重影响了系统吞吐率
- 现存系统对分布式支持弱，很难分区存储消息在不同机器上
- 假设了消息会被立即消费，所以存储消息的队列容量小。如果消息堆积，系统性能会变差。  

设计者对日志收集场景的分析：  
- 数据量大
- Facebook的Scribe等消息系统只支持离线分析场景
- LinkedIn需要支持秒级延迟的在线分析场景
- 因此Kafka诞生了，结合了传统消息系统和日志收集器的优点。一方面Kafka是分布式的，scalable，有高throughput（吞吐率）；另一方面Kafka提供了接近消息系统的API，并且支持实时消息处理。

# 总结
可以看到，Kafka被设计出来要支持的场景是 **在线场景下实时日志数据的处理** ，这点非常重要，因为Kafka的很多设计都是为了这个场景服务。
- 可扩展：分布式
- 日志数据量大：高吞吐
- 在线实时：低延迟
